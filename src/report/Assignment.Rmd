---
documentclass: article
fontsize: 10pt
date: "`r Sys.Date()`"
output: 
  bookdown::pdf_document2: 
    fig_caption: true
    toc: false
    latex_engine: xelatex
    includes:
      in_header: preamble.sty
      before_body: titlepage.sty
bibliography: references.bib  
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE, message=FALSE, warning=FALSE, appendix=TRUE}
#---------------------------load all packages----------------------------------#
library(tidyverse) # data wrangling and visualisation
library(rprojroot) # relative file paths
library(kableExtra)# tables in markdown
library(git2rdata) # clean, git-friendly datasets
library(patchwork) # combining several plots into one
library(brms)      # fitting Bayesian models
library(bayesplot) # visualise MCMC and posterior predictive checks
library(tidybayes) # wrangling and visualising Bayesian models

# Conflicts between packages
conflicted::conflicts_prefer(dplyr::filter)
conflicted::conflicts_prefer(dplyr::lag)
conflicted::conflicts_prefer(brms::ar)
conflicted::conflicts_prefer(brms::dstudent_t)
conflicted::conflicts_prefer(brms::pstudent_t)
conflicted::conflicts_prefer(brms::qstudent_t)
conflicted::conflicts_prefer(brms::rstudent_t)
conflicted::conflicts_prefer(dplyr::pull)
conflicted::conflicts_prefer(dplyr::group_rows)
conflicted::conflict_prefer("rhat", "brms")

knitr::opts_chunk$set(echo = FALSE, message = FALSE)
knitr::opts_knit$set(
  root.dir = find_root(criterion = has_file("stat_cons_disney.Rproj")))

#----------------------------Load all necessary data---------------------------#
waiting_times <- read_vc(file = "waiting_times",
                         root = find_root_file("data",
                                               criterion =
                                                 has_file(
                                                   "stat_cons_disney.Rproj"))) #SPOSTMIN:  Value -999 indicates the attraction was closed
file_to_ride <- read_vc(file = "file_to_ride",
                        root = find_root_file("data",
                                              criterion =
                                                has_file(
                                                  "stat_cons_disney.Rproj")))
entities_extra <- read_csv(find_root_file("data", "entities_extra.csv",
                                              criterion =
                                                has_file(
                                                  "stat_cons_disney.Rproj")))
metadata <- read_csv(find_root_file("data", "metadata.csv",
                                              criterion =
                                                has_file(
                                                  "stat_cons_disney.Rproj")))
```

# Introduction

This report investigates the accuracy of the posted waiting times for different Disney World attractions. 
More concrete, this report investigates the difference between the posted waiting time when a customer start queueing and the actually realised waiting time.
For transparency, all source code for this report and the data analysis can be found in a github repository [@Carmen_Disney_world_waiting].

Although the waiting times for `r n_distinct(file_to_ride$file)` attractions are available, this report focuses on `r n_distinct(file_to_ride %>% dplyr::filter(!is.na(code)) %>% dplyr::pull(file))` attractions for which metadata is available.
Some attractions have more than one opening date.
Since it is unclear whether this means that there is more than one attraction with the same name or whether it pertains to a renewal of the attraction, the latter is assumed, meaning the last opening date is the only relevant one.

```{r}
#filter the metadata to only keep attractions with metadata and only one row per file (keep last opening date):
file_to_ride <- file_to_ride %>%
  dplyr::filter(!is.na(code)) %>%
  arrange(file, opened_on) %>%
  group_by(file, short_name) %>%
  slice_tail() %>%#keep only the last occurance
  ungroup()
```

To work with the waiting times, some assumptions were made:

1. The posted times are supposed to inform customers on the expected time that they will queue if they *start* queueing at any given time. This means that the prediction model that Disney world uses, tries to predict the time that a customer will have to wait **at the moment he starts queueing**.
2. The posted times do not change between two registered posted times in the data.
3. The actual waiting time of a customer is subtracted from the time when his waiting time was registered (assuming this is the time when he entered the ride and thus stopped waiting) to know the time he started waiting. We then compare the posted waiting time at this calculated time with his actual waiting time.
4. Very little actual waiting times are registered each day for each attraction (Figure  \@ref(fig:nb-waiting-times-reg) in the appendix). It is assumed that the customers whose actual waiting time is registered are randomly selected.

# Data exploration

## Waiting times

In total, there are `r nrow(waiting_times)` actual waiting times over all `r n_distinct(file_to_ride$file)` attractions, registered between `r as.Date(min(waiting_times$datetime))` and `r as.Date(max(waiting_times$datetime))`.
Removing waiting times for which the posted waiting time was either missing or "-999" (meaning the ride was closed), `r sum(!is.na(waiting_times$posted_at_start_wait) &  waiting_times$posted_at_start_wait != -999)` waiting times remain.
Additionally, there are some outliers in the realized waiting times.
Removing all negative waiting times and waiting times larger than 360 minutes, `r sum(!is.na(waiting_times$posted_at_start_wait) &  waiting_times$posted_at_start_wait != -999 & waiting_times$SACTMIN >= 0 & waiting_times$SACTMIN <= 360)` waiting times remain.
It should be noted that each attraction does not have the same amount of waiting times due to the fact that the time period of data collection (Figure \@ref(fig:date-collection) in the appendix) and the number of collected waiting times per day (Figure \@ref(fig:nb-waiting-times-reg) in the appendix) differs per attraction.

```{r}
#keep only waiting times with corresponding posted waiting time:
waiting_times <- waiting_times %>%
  dplyr::filter(!is.na(posted_at_start_wait) &  posted_at_start_wait != -999 &
                  SACTMIN >= 0 & SACTMIN <= 360) %>%
  mutate(diff = posted_at_start_wait - SACTMIN)
set.seed(2024)
sample <- waiting_times %>%
  slice_sample(n = 10000) 
```


Figure \@ref(fig:waiting-exploration) explores the difference between the actual and posted waiting times.
In the top left figure, the posted waiting time overestimates the actual waiting time for observations above the diagonal line.
The color corresponds to the difference between the posted and actual waiting time.
The top right figure also clearly shows that it is more likely that the actual waiting time is overestimated than underestimated (it is overestimated in approximately `r round(100*sum(sample$diff>0) / nrow(sample))`% of cases).
It is likely that this tendency to overestimate the waiting time is a tactical choice since it has been shown that people generally get more agitated if they need to wait longer than expected.
Since the posted waiting time will strongly influence the expected waiting times, it makes sense to overestimate rather than to underestimate the waiting time (see for instance @maister1984psychology and @chu2019psychology).
The bottom figures show the mean and 95% confidence interval of the actual waiting time (left) and the difference between the posted and actual waiting time (right) over the day, depending on when the client started to wait.
In the appendix, each of these figures are shown for each of the attractions separately (Figure \@ref(fig:waiting-exploration-app1) to \@ref(fig:waiting-exploration-app4) in the appendix).

```{r waiting-exploration, fig.cap = "Exploration of actual and posted waiting time and the difference between both."}
#keep only waiting times with corresponding posted waiting time:
p1 <- sample %>%
  ggplot() +
  geom_line(data = data.frame(x = c(0, max(sample$SACTMIN)),
                              y = c(0,max(sample$posted_at_start_wait))),
            aes(x = x, y = y)) +
  geom_point(aes(x = SACTMIN, y = posted_at_start_wait, color = diff),
             alpha = 0.5) +
  scale_color_gradientn("Difference",
                        colours =
                          c("yellow", "orange", "red", "darkred")) +
  xlab("Actual waiting time (min)") +
  ylab("Posted waiting time (min)") +
  guides(colour = "none") +
  theme_bw()
bin_width <- 10
nbins = ceiling((max(sample$diff) - min(sample$diff))/bin_width)
colfunc <- colorRampPalette(c("yellow", "orange", "red", "darkred"))

p2 <- sample %>%
  ggplot() +
  geom_histogram(aes(x = diff, y = after_stat(count / sum(count))),
                 binwidth = bin_width,
                 fill = colfunc(nbins),
                 alpha = 0.8) +
  geom_vline(aes(xintercept = 0), color = "black") +
  scale_y_continuous(labels = scales::percent) +
  ylab("Percentage of observations") +
  xlab("Posted - actual waiting time (min)") +
  theme_bw()

p4 <- waiting_times %>%
  mutate(
    start_wait = datetime - as.difftime(SACTMIN, units = "mins"),
    hour = hour(start_wait)) %>%
  group_by(hour) %>%
  summarize(mean = mean(diff),
            st_dev = sd(diff),
            nb = n(),
            lower = mean - 1.95 * st_dev/sqrt(nb),
            upper = mean + 1.95 * st_dev/sqrt(nb)) %>%
  ungroup() %>%
  filter(hour >= 6 & hour <= 23) %>%
  ggplot(aes(x = hour, y = mean)) +
  geom_ribbon(aes(ymin = lower, ymax = upper),
              alpha = 0.5) +
  geom_line() +
  theme_bw() +
  scale_x_continuous(breaks = seq(6, 23, 3)) +
  ylab("Posted - actual waiting time (min)") +
  xlab("Time of day (hour)")
p3 <- waiting_times %>%
  mutate(
    start_wait = datetime - as.difftime(SACTMIN, units = "mins"),
    hour = hour(start_wait)) %>%
  group_by(hour) %>%
  summarize(mean = mean(SACTMIN),
            st_dev = sd(SACTMIN),
            nb = n(),
            lower = mean - 1.95 * st_dev/sqrt(nb),
            upper = mean + 1.95 * st_dev/sqrt(nb)) %>%
  ungroup() %>%
  filter(hour >= 6 & hour <= 23) %>%
  ggplot(aes(x = hour, y = mean)) +
  geom_ribbon(aes(ymin = lower, ymax = upper),
              alpha = 0.5) +
  geom_line() +
  theme_bw() +
  scale_x_continuous(breaks = seq(6, 23, 3)) +
  ylab("Actual waiting time (min)") +
  xlab("Time of day (hour)")


p1 + p2 + p3 + p4
```

## Metadata

In addition to the waiting times, the source files contain a rich dataset with metadata on both the attractions and seasonal aspects.
The variables in Table \@ref(tab:covariates) are selected as possible covariates in our data.
This selection of covariates is based on expert opinion, taking care not to include highly correlated variables.

```{r covariates}
waiting_times_reg <- waiting_times %>%
  left_join(metadata %>%
              dplyr::select(DATE, DAYOFWEEK, YEAR, HOLIDAYPX, WDW_TICKET_SEASON,
                            WDWMEANTEMP, inSession, MKPRDDAY,
                            CapacityLostWGT_MK, CapacityLostWGT_AK,
                            CapacityLostWGT_EP, CapacityLostWGT_HS) %>%
              mutate(WDW_TICKET_SEASON = ifelse(is.na(WDW_TICKET_SEASON),
                                                "regular", WDW_TICKET_SEASON)),#assume NA = "regular"-> should adjust this in metadata before join (NA here then means that date wasn't available in the metadata file)
            by = join_by(date == DATE)) %>%
  left_join(file_to_ride %>%
              dplyr::select(file, short_name, land),
            by = join_by(file == file)) %>%
  left_join(entities_extra %>%
              dplyr::select(short_name, duration, category_code, 
                            scope_and_scale_code),
            by = join_by(short_name == short_name)) %>%
  mutate(start_wait = datetime - as.difftime(SACTMIN, units = "mins"),
         hour = hour(start_wait),
         mins = minute(start_wait),
         tod = hour + mins/60,
         inSession = as.numeric(str_remove(inSession, "%")),
         DAYOFWEEK = as.factor(DAYOFWEEK),
         YEAR = as.factor(YEAR),
         WDW_TICKET_SEASON = as.factor(WDW_TICKET_SEASON),
         scope_and_scale_code = as.factor(scope_and_scale_code)
         ) %>%
  #dplyr::select(-hour, -mins) %>%
  mutate(CapacityLostWGT_AK = scale(CapacityLostWGT_AK, center = TRUE,
                                    scale = TRUE),
         CapacityLostWGT_MK = scale(CapacityLostWGT_MK, center = TRUE,
                                    scale = TRUE),
         CapacityLostWGT_EP = scale(CapacityLostWGT_EP, center = TRUE,
                                    scale = TRUE),
         CapacityLostWGT_HS = scale(CapacityLostWGT_HS, center = TRUE,
                                    scale = TRUE),
         CapacityLostWGT = (CapacityLostWGT_AK + CapacityLostWGT_MK +
                              CapacityLostWGT_EP + CapacityLostWGT_HS)/4,
         tod2 = tod * tod, #time of day squared
         land = as.factor(land),
         category_code = as.factor(category_code),
         short_name = as.factor(short_name),
         weekend = 1*(DAYOFWEEK %in% c("6", "7")))
covariates <- data.frame(
  covariate = c("weekend", "HOLIDAYPX", "WDW_TICKET_SEASON", 
                "WDWMEANTEMP", "inSession", "MKPRDDAY", "CapacityLostWGT", 
                "duration", "category_code", "scope_and_scale_code", "tod"),
  label = c("weekend", "holidayPX", "ticket_season", 
            "mean_temp", "schools", "nb_parades", "capacity_lost", 
            "duration", "category_code", "scope_and_scale_code", "tod"),
  expl = c("Whether it is a weekend date (TRUE) or not (FALSE). Day of the week was also
           tested in the model exploration phase.",
           "Proximity to Holiday (2-directional) (in days)",
           "Walt Disney World Single Day Price Type (peak, regular, or value)",
           "Average temperature this day",
           "The percentage of schools in session",
           "Number of Daytime Parades at Magic Kingdom",
           "Total hourly capacity lost on that park day, weighted by attraction popularity. This covariate is centered and normalized.",
           "Duration of attraction in minutes",
           "The type of attraction (character_greeting, continuous_show, or ride)",
           "The type of attraction (headliner, major_attraction, minor_attraction, or  super_headliner)",
           "Time of day (in hours)"),
  type = c("binary", "numeric", "discrete", "numeric", "numeric", "numeric",
           "numeric", "numeric", "discrete", "discrete", "numeric"))
covariates %>%
  dplyr::select(label, type, expl) %>%
  kable(col.names = c("Covariate", "Type", "Explanation"),
        caption = "Overview of all covariates.",
        format = "latex",
        booktabs = TRUE) %>%
  kableExtra::kable_styling() %>%
  column_spec(3, width = "4in")
```

It should be noted that, since this metadata is not available for all dates and attractions, out dataset  is reduced to `r waiting_times_reg[complete.cases(waiting_times_reg),] %>% nrow()` waiting times for `r waiting_times_reg[complete.cases(waiting_times_reg),] %>% dplyr::pull(short_name) %>% n_distinct()` attractions.

# Methodology and Results

A linear regression is fit to predict the difference between the posted and actual waiting time ($Y$) based on the covariates in Table \@ref(tab:covariates). A Bayesian model is fit in R, using the *brms* package [@burkner2017brms]. To account for the fact that waiting times originate from `r waiting_times_reg[complete.cases(waiting_times_reg),] %>% dplyr::pull(short_name) %>% n_distinct()` attractions, a random intercept is added for the attractions [@burkner2017advanced].

```{r}
#Maybe use multiple imputation to predict at least the daily variables??
# https://cran.r-project.org/web/packages/brms/vignettes/brms_missings.html

waiting_times_reg <- waiting_times_reg[complete.cases(waiting_times_reg),]
  
# correlation_matrix <- cor(waiting_times_reg %>%
#                             dplyr::select(where(is.numeric)))
# library(corrplot)
# corrplot(correlation_matrix, type = "upper", order = "hclust",
#          tl.col = "black", tl.srt = 45)

```

Before drawing any conclusions from the model results, MCMC convergence is checked (Appendix \@ref(model-convergence)).
Convergence is good so Figures \@ref(fig:fixed) and \@ref(fig:random) show the results for the fixed and random effects respectively.
As the dependent variable, $Y$, is equal to difference between the posted and actual waiting time:

- Positive $Y$ means that the posted waiting time exceeds the actual waiting time. Positive coefficients therefore imply that the covariate will lead to a higher tendency to overestimate the actual waiting time.
- Negative $Y$ means that the posted waiting time is lower than the actual waiting time. Negative coefficients therefore imply that the covariate will lead to a higher tendency to underestimate the actual waiting time.

```{r eval = TRUE}
mod <- readRDS(file = find_root_file("data", "model.rds",
                                     criterion =
                                       has_file(
                                         "stat_cons_disney.Rproj")))
# Set MCMC parameters
nchains <- 3 # number of chains
niter <- 2000 # number of iterations (incl. burn-in, see next)
burnin <- niter / 4 # number of initial samples to remove (= burn-in)
nparallel <- nchains # number of cores for parallel computing
thinning <- 1 #
s <- summary(mod, prob = 0.90)
#pred <- predict(mod)
#save(pred, file = find_root_file("data", "prediction.Rdata",
                                     # criterion =
                                     #   has_file(
                                     #     "stat_cons_disney.Rproj")))
load(file = find_root_file("data", "prediction.Rdata",
                                     criterion =
                                       has_file(
                                         "stat_cons_disney.Rproj")))
```

```{r eval = FALSE}
#https://biol609.github.io/lectures/23c_brms_prediction.html#32_fixed_and_random_effects
# library(glmmTMB)
# test <- glmmTMB(diff ~ DAYOFWEEK + HOLIDAYPX + WDW_TICKET_SEASON +
#                   WDWMEANTEMP + inSession + MKPRDDAY + category_code +
#                   duration + scope_and_scale_code + tod +
#                   CapacityLostWGT + (1|short_name),
#                 data = waiting_times_reg,
#                 family = gaussian())
#Model convergence problem; non-positive-definite Hessian matrix
# Set MCMC parameters
nchains <- 3 # number of chains
niter <- 2000 # number of iterations (incl. burn-in, see next)
burnin <- niter / 4 # number of initial samples to remove (= burn-in)
nparallel <- nchains # number of cores for parallel computing
thinning <- 1 #

# test <- brm(diff ~ DAYOFWEEK + YEAR + HOLIDAYPX + WDW_TICKET_SEASON +
#                   WDWMEANTEMP + inSession + MKPRDDAY + category_code +
#                   duration + scope_and_scale_code + tod + tod2 + tod3 +
#                   CapacityLostWGT + (1|land/short_name),
#             data = waiting_times_reg,
#             family = gaussian)
mod2 <- brm(diff ~ weekend + HOLIDAYPX + WDW_TICKET_SEASON +
                  WDWMEANTEMP + inSession + MKPRDDAY + duration +
              scope_and_scale_code + tod + tod2 +
              CapacityLostWGT + (1|short_name),
            data = waiting_times_reg,
            family = gaussian(),
            chains = nchains,            # MCMC parameters
            warmup = burnin, 
            iter = niter,
            cores = nparallel,
            thin = thinning,
            seed = 123,
            file = find_root_file("data", "model6",
                                              criterion =
                                                has_file(
                                                  "stat_cons_disney.Rproj")),
            file_refit = "on_change")#to make it faster

summary(test)
plot(test)
s <- summary(mod, prob = 0.90)
```

As was already evident from the data analysis (Section \@ref(waiting-times) and Appendix \@ref(difference-between-the-actual-and-posted-waiting-times-per-attraction)), the waiting time tends to be overestimated. This is confirmed by the posterior predictive distribution of $Y$ (Figure \@ref(fig:ppd) in the appendix). 

Figure \@ref(fig:fixed) shows the estimated coefficients with confidence intervals. 

Waiting times are overestimated significantly more if (*covariate* estimate [lower 90% CI, upper 90% CI]):

- there is a lot of capacity lost (*capacity_lost* `r sprintf("%.3f [%.3f, %.3f]", s$fixed["CapacityLostWGT",1], s$fixed["CapacityLostWGT",3], s$fixed["CapacityLostWGT",4])`)
- it is later in the day (*tod* `r sprintf("%.3f [%.3f, %.3f]", s$fixed["tod",1], s$fixed["tod",3], s$fixed["tod",4])`)
- it is a weekend day (*weekendTRUE* `r sprintf("%.3f [%.3f, %.3f]", s$fixed["weekendTRUE",1], s$fixed["weekendTRUE",3], s$fixed["weekendTRUE",4])`)

Waiting times are overestimated significantly less (*covariate* estimate [lower 90% CI, upper 90% CI]):

- for minor_attraction than for headliners (*scope_and_scale_codeminor_attraction* `r sprintf("%.3f [%.3f, %.3f]", s$fixed["scope_and_scale_codeminor_attraction",1], s$fixed["scope_and_scale_codeminor_attraction",3], s$fixed["scope_and_scale_codeminor_attraction",4])`)
- for continuous shows than for character greetings (*category_codecontinuous_show* `r sprintf("%.3f [%.3f, %.3f]", s$fixed["category_codecontinuous_show",1], s$fixed["category_codecontinuous_show",3], s$fixed["category_codecontinuous_show",4])`)
- if there are more parades (*nb_parades* `r sprintf("%.3f [%.3f, %.3f]", s$fixed["MKPRDDAY",1], s$fixed["MKPRDDAY",3], s$fixed["MKPRDDAY",4])`)
- if less schools are closed (*schools* `r sprintf("%.3f [%.3f, %.3f]", s$fixed["inSession",1], s$fixed["inSession",3], s$fixed["inSession",4])`)
- if the temperature is higher (*mean_temp* `r sprintf("%.3f [%.3f, %.3f]", s$fixed["WDWMEANTEMP",1], s$fixed["WDWMEANTEMP",3], s$fixed["WDWMEANTEMP",4])`)
- if value tickets are being sold (*ticket_seasonvalue* `r sprintf("%.3f [%.3f, %.3f]", s$fixed["WDW_TICKET_SEASONvalue",1], s$fixed["WDW_TICKET_SEASONvalue",3], s$fixed["WDW_TICKET_SEASONvalue",4])`)


```{r fixed, fig.cap = "Results for the fixed effects model. The errorbars show 30%, 60%, and 90% confidence intervals. Blue estimates are significantly lower than zero while red estimates are significantly higher than zero (at 90% confidence)", message = FALSE, warning = FALSE}
s90 <- summary(mod, prob = 0.90)
s60 <- summary(mod, prob = 0.60)
s30 <- summary(mod, prob = 0.30)


lbl <- rownames(s90$fixed)
for (x in seq_len(nrow(covariates))) {
  lbl <- str_replace(lbl,
                     covariates[x, "covariate"],
                     covariates[x, "label"])
}
labels <- 
  data.frame(raw = rownames(s90$fixed),
             label = lbl)

p <- s90$fixed %>% 
  left_join(s30$fixed) %>%
  left_join(s60$fixed) %>%
  cbind(data_frame(par = rownames(s90$fixed))) %>%
  mutate(color = ifelse(`l-90% CI` > 0, "red",
                       ifelse(`u-90% CI` < 0, "blue",
                              "black"))) %>%
  ggplot(aes(x = par, y = Estimate, color = color)) +
  geom_point(size = 2) + 
  geom_linerange(aes(ymin = `l-90% CI`, ymax = `u-90% CI`), linewidth = 0.5) +
  geom_linerange(aes(ymin = `l-60% CI`, ymax = `u-60% CI`), linewidth = 1) +
  geom_linerange(aes(ymin = `l-30% CI`, ymax = `u-30% CI`), linewidth = 1.5) +
  geom_hline(aes(yintercept = 0), color = "black") +
  coord_flip() +
  theme_bw() +
  scale_color_manual("",
                       breaks = c("blue", "black", "red"),
                       values = c("#005AB5", "black", "#DC3220")) +#colorblind friendly
  theme(legend.position = "none") +
  scale_x_discrete(name = "",
                   limits = labels$raw,
                   labels = labels$label)
p
  

```

Figure \@ref(fig:random) shows the random effect for each of the attractions. These random effects correct for any deviations in $Y$ which cannot be explained by the fixed effects.
An attraction with an estimated random effect around zero, would have an expected $Y$ that is very close to what is expected from the fixed effects model.
It can be seen that the posted waiting times for the *7 Dwarfs train* will overestimate the actual waiting times much more than would be expected based on the fixed effects model alone.
In contrast, *Regal Carrousel* will overestimate the actual waiting time much less.

```{r random, fig.cap = "Random effect for each of the attractions, sorted from highest to lowest difference between posted and actual waiting time."}
sd_mean <- mod %>%
  spread_draws(sd_short_name__Intercept, ndraws = 1000, seed = 123) %>%
  summarise(mean_sd = mean(sd_short_name__Intercept)) %>%
  pull()

# Neem random effects en plot
mod %>%
  spread_draws(r_short_name[short_name,], ndraws = 1000, seed = 123) %>%
  ungroup() %>%
  mutate(short_name = reorder(short_name, r_short_name)) %>%
  ggplot(aes(x = r_short_name, y = short_name)) +
    geom_vline(xintercept = 0, color = "darkgrey", linewidth = 1) +
    geom_vline(xintercept = c(sd_mean * qnorm(0.05), sd_mean * qnorm(0.95)),
               color = "darkgrey", linetype = 2) +
    stat_halfeye(point_interval = "median_qi", .width = 0.9, size = 2/3,
                 fill = "cornflowerblue") +
  theme_bw() +
  ylab("Attraction") +
  xlab("Random intercept")
```

\clearpage

# Conclusion
## Discussion

Firstly, several interesting conclusions can be drawn from the exploratory data analysis. The posted waiting times are pretty close to the actual waiting times meaning Disney World's waiting time prediction models work well. It could be concluded that posted waiting times tend to slightly overestimate the actual waiting time rather than underestimate it. This is good since this will manage expectations and lead to more customer satisfaction.

The statistical model allows to identify certain conditions when the difference between posted and actual waiting times is larger or smaller. Based on this model, it is advised to revise the predictions during weekends and later in the day since the waiting times are overestimated even more during these periods. Waiting times are also overestimated more for headliner and for character greeting attractions.
The random effects for the attractions revealed that the prediction accuracy significantly differs for some attractions. Posted waiting times for *7 Dwarfs Train*, *Peter Pan's Flight*, and *Buzz Lightyear* overestimated the actual waiting time significantly more than for the average attraction. Posted waiting times for *Regal Carrousel* and *Pirates of Caribbean* underestimated the actual waiting time significantly more than for the average attraction. It is advised to review the prediction model for these attractions and look for possible driving factors for this discrepancy. 


## Recommendations for future research

To improve the current analysis, some additional information may be useful. Some of the current covariates seem to be proxies for the popularity of the attraction and the overall business in Disney World. Variables such as throughput per attraction per day and the overall number of visitors in Disney World measure these variables  more directly and may help to assess prediction accuracy.

Additionally, there were many missing values in the metadata. This more than halved the number of available waiting times from 186173 waiting times for 52 attractions to 71796 for 25 attractions. It is unclear whether or not losing these observations biases our results. Further information from field experts is needed to assess why some metadata is missing and whether the missingness can be assumed to be random. Multiple imputation may be used to limit the number of observations that are lost due to the missingness. 

Currently, covariates were selected based on expert opinion, making sure not to include highly correlated variables. 
For future research, it would be valuable to include additional covariates, even if they are highly correlated, and use variable selection techniques such as LASSO and Elastic Net (see for instance @ariyo2020bayesian). 

\clearpage

\appendix

# Appendix

## Number of registered waiting times

```{r nb-waiting-times-reg, fig.cap="Mean number of registered actual waiting times per day (and 95% conf. int.) for the different attractions.", fig.height = 4, fig.width = 8}
ndays <- waiting_times %>%
  group_by(file, date) %>%
  summarize(n = n()) %>%
  summarize(mean = mean(n),
            st_dev = sd(n),
            ndays = n()) %>%
  mutate(lower = mean - 1.95 * st_dev/sqrt(ndays),
         upper = mean + 1.95 * st_dev/sqrt(ndays)) %>%
  ungroup() %>%
  arrange(mean) %>%
  left_join(file_to_ride)
ndays %>%
  ggplot(aes(x = file, y = mean, ymin = lower, ymax = upper,
             color = land)) +
  geom_pointrange(fatten = 2) +
  scale_x_discrete(name = "Attraction", breaks = ndays$file, limits = ndays$file,
                   labels = str_wrap(ndays$short_name, width = 15)) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1, size = 8),
        legend.text = element_text(size = 8),
        legend.position = "bottom",
        legend.margin = margin(0,0,0,0),
        legend.box.margin = margin(-10,-10,-10,-10)) +
  ylab("Nb actual waiting times per day")
```

```{r date-collection, fig.cap="Period of data collection for each attraction. Color shows the total number of registered waiting times", fig.height = 4, fig.width = 8}
start_end <- waiting_times %>%
  mutate(date = ymd(as.Date(datetime))) %>%
  group_by(file) %>%
  summarize(ymin = min(date),
            ymax = max(date),
            nb = n()) %>%
  ungroup() %>%
  mutate(ymin = as.Date(ymin),
         ymax = as.Date(ymax)) %>%
   arrange(nb) %>%
  left_join(file_to_ride)
start_end %>%
  ggplot(aes(x = file, ymin = ymin, ymax = ymax, color = nb)) +
  geom_linerange(linewidth = 2)  +
  scale_y_date(date_labels = "%m/%Y") +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1, size = 8),
        legend.text = element_text(size = 8),
        legend.position = "bottom",
        legend.margin = margin(0,0,0,0),
        legend.box.margin = margin(-10,-10,0,-10)) +
  scale_x_discrete(name = "Attraction", breaks = start_end$file,
                   limits = start_end$file,
                   labels = str_wrap(ndays$short_name, width = 15)) +
  scale_color_gradientn("Nb waiting\n times",
                        colours =
                          c("yellow", "orange", "darkred"))

```

\clearpage

## Difference between the actual and posted waiting times per attraction

Figure \@ref(fig:waiting-exploration-app1) shows the posted versus actual waiting times. *Enchanted Tiki Run* and *Flight of Passage* stand out for the shortest and longest posted and actual waiting times. The most extremely underestimated waiting times (in yellow) can be found in the *Soarin'* and *Flight of Passage* attractions.

Figure \@ref(fig:waiting-exploration-app2) shows a histogram of the difference between the posted and actual waiting time. The percentage in the top right corner indicates the percentage of observations where the posted waiting time exceeds the actual waiting time. *Regal Carrousel* stands out since it is the only attraction where less than half of the waiting times are overestimated. 


Figure \@ref(fig:waiting-exploration-app3) shows the actual waiting time over the day. The mean and confidence interval are only shown if there are at least 5 customers who started waiting at that hour of the day and whose waiting time was registered. *Flight of Passage* and *7 Dwarfs Train* stand out since they have the highest waiting times. *Flight of Passage* has consistently high waiting times while most other attractions show a daily pattern with the highest waiting times between 10AM and 3PM.

Figure \@ref(fig:waiting-exploration-app4) shows the difference between the posted and actual waiting times over the day. The mean and confidence interval are only shown if there are at least 5 customers who started waiting at that hour of the day and whose waiting time was registered. Most attractions show higher overestimations of the waiting time as the day progresses (especially noticeable in *Flight of Passage*, *7 Dwarfs Train*, and *Rock Coaster*)

```{r waiting-exploration-app1, fig.cap = "Exploration of actual and posted waiting time.", fig.width = 8, fig.height = 12}
samplesize <- 2000 #keep at most this many waiting times per attraction to keep the figure manageable.
counts <- waiting_times %>%
  group_by(file) %>%
  tally()
waiting_times %>%
  dplyr::filter(file %in% (waiting_times %>%
                             group_by(file) %>%
                             tally() %>%
                             dplyr::filter(n > samplesize) %>%
                             dplyr::pull(file))) %>%
  group_by(file) %>%
  slice_sample(n = 2000) %>%
  ungroup() %>%
  rbind(waiting_times %>%
          dplyr::filter(file %in% (waiting_times %>%
                             group_by(file) %>%
                             tally() %>%
                             dplyr::filter(n <= samplesize) %>%
                             dplyr::pull(file)))) %>%
  left_join(file_to_ride) %>%
  ggplot() +
  geom_line(data = data.frame(x = c(0, max(sample$SACTMIN)),
                              y = c(0,max(sample$posted_at_start_wait))),
            aes(x = x, y = y)) +
  geom_point(aes(x = SACTMIN, y = posted_at_start_wait, color = diff),
             alpha = 0.5) +
  scale_color_gradientn("Difference",
                        colours =
                          c("yellow", "orange", "red", "darkred")) +
  facet_wrap(vars(short_name), nrow = 6) +
  xlab("Actual waiting time (min)") +
  ylab("Posted waiting time (min)") +
  guides(colour = "none") +
  theme_bw()
```

```{r waiting-exploration-app2, warning = FALSE, fig.cap = "Histogram of the difference between posted and actual waiting time.", fig.width = 8, fig.height = 12}
percentage_overestimated <- waiting_times %>%
  mutate(diff = posted_at_start_wait - SACTMIN) %>%
  group_by(file) %>%
  summarize(n_over = sum(diff > 0),
            perc = paste0(round(100 * n_over/n()), "%")) %>%
  left_join(file_to_ride)

waiting_times %>%
  mutate(diff = posted_at_start_wait - SACTMIN) %>%
  left_join(file_to_ride) %>%
  ggplot() +
  geom_histogram(aes(x = diff, y = after_stat(density) * bin_width),
                 binwidth = bin_width,
                 alpha = 0.8) +
  geom_vline(aes(xintercept = 0), color = "black") +
  geom_text(data = percentage_overestimated,
             aes(x = 75, y = 0.6, label = perc)) +
  scale_y_continuous(labels = scales::percent) +
  facet_wrap(vars(short_name), nrow = 6) +
  ylab("Percentage of observations") +
  xlab("Posted - actual waiting time (min)") +
  xlim(c(-100, 100)) +
  theme_bw()
```

```{r waiting-exploration-app3, fig.cap = "Exploration of the actual waiting time over the day.", fig.width = 8, fig.height = 12}
waiting_times %>%
  mutate(
    start_wait = datetime - as.difftime(SACTMIN, units = "mins"),
    hour = hour(start_wait)) %>%
  group_by(hour, file) %>%
  summarize(mean = mean(SACTMIN),
            st_dev = sd(SACTMIN),
            nb = n(),
            lower = mean - 1.95 * st_dev/sqrt(nb),
            upper = mean + 1.95 * st_dev/sqrt(nb)) %>%
  ungroup() %>%
  left_join(file_to_ride) %>%
  filter(hour >= 6 & hour <= 23 & nb > 5) %>%
  ggplot(aes(x = hour, y = mean)) +
  geom_ribbon(aes(ymin = lower, ymax = upper),
              alpha = 0.5) +
  geom_line() +
  theme_bw() +
  facet_wrap(facets = vars(short_name),
             nrow = 6) +
  scale_x_continuous(breaks = seq(6, 23, 3)) +
  ylab("Actual waiting time (min)") +
  xlab("Time of day (hour)")
```

```{r waiting-exploration-app4, fig.cap = "Difference between the posted and actual waiting time over the day.", fig.width = 8, fig.height = 12}
waiting_times %>%
  mutate(
    start_wait = datetime - as.difftime(SACTMIN, units = "mins"),
    hour = hour(start_wait)) %>%
  group_by(hour, file) %>%
  summarize(mean = mean(diff),
            st_dev = sd(diff),
            nb = n(),
            lower = mean - 1.95 * st_dev/sqrt(nb),
            upper = mean + 1.95 * st_dev/sqrt(nb)) %>%
  ungroup() %>%
  filter((hour >= 6 & hour <= 23) & nb > 5) %>% # we need at least 5 waiting times to reliably calculate conf int
  left_join(file_to_ride) %>%
  ggplot(aes(x = hour, y = mean)) +
  geom_ribbon(aes(ymin = lower, ymax = upper),
              alpha = 0.5) +
  geom_line() +
  theme_bw() +
  facet_wrap(facets = vars(short_name),
             nrow = 6) +
  scale_x_continuous(breaks = seq(6, 24, 6)) +
  ylab("Posted - actual waiting time (min)") +
  xlab("Time of day (hour)")  +
  scale_y_continuous(limits = c(-10, NA))
```

\clearpage

## Model convergence

To fit a Bayesian model, information on the distribution is obtained by sampling using the "Markov Chain Monte Carlo" (MCMC) method. When using this method, it is important to check MCMC convergence.

Our MCMC was run with `r nchains` chains with `r niter` iterations each. The burn-in period is `r niter / 4` iterations. The default, flat priors were used for all parameter estimates. Visually, the trace plots showed good mixing and convergence (Figure \@ref(fig:trace)), as do the posterior density plots (Figure \@ref(fig:pdp)). The Gelman-Rubin diagnostics show that all $\hat{R}$ (R-hats) are close to 1 (Figure \@ref(fig:rhat)). Lastly, the effective sample size seems to be large enough for most parameters (Figure \@ref(fig:neff)). Although it could be better for the *category_code* covariate. We can therefore conclude that convergence is sufficient.

```{r trace, fig.cap = "Trace plots for each of the parameters. The colors show the different chains.", warning = FALSE, message = FALSE, fig.width = 8, fig.height = 12}
s <- summary(mod)
parameters <- c(paste0("b_", rownames(s$fixed)), "sigma")
a <- as_draws_df(mod, variable = parameters) %>%
  # long format
  pivot_longer(cols = all_of(parameters), names_to = "parameter",
               values_to = "value")
for (x in seq_len(nrow(covariates))) {
  a$parameter <- str_replace(a$parameter,
                     covariates[x, "covariate"],
                     covariates[x, "label"])
}

a %>%
  # visualise with ggplot()
  ggplot(aes(y = value, x = .iteration, colour = factor(.chain))) +
    geom_line(alpha = 0.8) +
    facet_wrap(~parameter, ncol = 3, scales = "free") +
  theme_bw() +
  scale_color_discrete("") +
  xlab("Iteration")
```

```{r pdp, fig.cap = "Posterior density plot for each of the parameters.", warning = FALSE, message = FALSE, fig.width = 8, fig.height = 12}
p <- mcmc_dens_overlay(mod, pars = parameters,
          facet_args = list(ncol = 4))
p$data$Parameter <- as.character(p$data$Parameter)
for (x in seq_len(nrow(covariates))) {
  p$data$Parameter <- str_replace(p$data$Parameter,
                     covariates[x, "covariate"],
                     covariates[x, "label"])
}
p
```

```{r rhat, fig.cap = "Gelman-Rubin diagnostics.", warning = FALSE, message = FALSE}
p <- mcmc_rhat(rhat(mod)[parameters]) + yaxis_text(hjust = 1)
p$data$parameter <- as.character(p$data$parameter)
for (x in seq_len(nrow(covariates))) {
  p$data$parameter <- str_replace(p$data$parameter,
                     covariates[x, "covariate"],
                     covariates[x, "label"])
}
p
```

```{r neff, fig.cap = "Ratio of effective sample size and the number of iterations.", warning = FALSE, message = FALSE}
p <- mcmc_neff(neff_ratio(mod)[parameters]) + yaxis_text(hjust = 1)
p$data$parameter <- as.character(p$data$parameter)
for (x in seq_len(nrow(covariates))) {
  p$data$parameter <- str_replace(p$data$parameter,
                     covariates[x, "covariate"],
                     covariates[x, "label"])
}
p
```

To check model fit, the posterior predictive distribution is compared to the actual distribution of the difference between the posted and actual waiting time. While the fit is not entirely bad (the estimated mean and median (`r round(mean(pred[,1]), 3)` and `r round(median(pred[,1]), 3)`), are close to the true mean and median, (`r round(mean(waiting_times_reg$diff), 3)` and `r round(median(waiting_times_reg$diff), 3)`)), the model does not quite succeed in capturing the true variance in $Y$. 


```{r ppd, fig.cap = "Posterior predictive distribution (PPD) for the difference between posted and actual waiting times. The colored histogram shows the raw data while the black outlines show the histogram for the PPD."}
bin_width <- 5
nbins = 70#ceiling((max(waiting_times_reg$diff) - min(waiting_times_reg$diff))/bin_width)
colfunc <- colorRampPalette(c("yellow", "orange", "red", "darkred"))
p2 <- sample %>%
  ggplot() +
  geom_histogram(aes(x = diff, y = after_stat(count / sum(count))),
                 binwidth = bin_width,
                 fill = colfunc(nbins),
                 alpha = 0.8) +
  scale_y_continuous(labels = scales::percent) +
  ylab("Percentage of observations") +
  xlab("Posted - actual waiting time (min)") +
  theme_bw() +
  geom_histogram(data = as.data.frame(pred),
                 aes(x = Estimate, y = after_stat(count / sum(count))),
                 binwidth = bin_width,
                 fill = colfunc(nbins),
                 alpha = 0,
                 color = "black") 
p2
```

\clearpage

# Bibliography
